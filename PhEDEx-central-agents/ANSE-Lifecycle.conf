# This is where it all happens...
%Lifecycle::Lite = (
  Name		=> 'ANSE Lifecycle', # don't worry about this...

# These are true global values. Overriding these per dataflow does not make sense
  Quiet		=> 0,
  Verbose	=> 0,
  Debug		=> 0,

  Jitter	=>  0.1, # Spread delay-times for workflow events by a small factor
  CycleSpeedup	=>    1, # speed up time. 1 => real-time, 7 => do a week of work in a day
  Suspend       =>    0, # set to 1 to suspend new workflows from starting,
                         # but allow existing workflows to run to completion
  NJobs         =>    8, # degree of parallelism

  TmpDir	=>  '/data/' . (getpwuid($<))[0] . '/tmp/', # Directory for temporary files.
  GarbageCycle  =>  300, # How often to run the garbage collector, to clean the TmpDir
  GarbageAge    => 3600, # How old a file can be before being garbage-collected

  StatsFrequency => 3600 * 12, # Provide internal statistics every so often

# Also true globals, but these make sense to override. Providing values here
# is just a convenient way to avoid having to repeat them everywhere.
  CycleTime     => 600,
  NCycles       => -1, # < 0 => infinite, > 0 to limit

  KeepInputs    => 0, # keep the  input files of successful jobs?
  KeepOutputs   => 0, # keep the output files of successful jobs?
  KeepLogs      => 0, # keep the    log files of successful jobs?
  KeepFailedInputs      => 1, # keep the  input files of failed jobs?
  KeepFailedOutputs     => 1, # keep the output files of failed jobs?
  KeepFailedLogs        => 1, # keep the    log files of failed jobs?

# Next, some global values that _can_ be overridden sensibly, per dataflow or per dataset
  FileSizeMean	 => 2.0, # GB
  FileSizeStdDev => 0.2, # GB

# After the global values, set the Dafaflow default values and dataset workflow
  Templates => {
#   Default parameters for each workflow. These override global defaults, but
#   are in turn overridden by values in the specific workflow instances.
#   Typically, set CycleTime and NFiles, based on the expectations from the
#   computing model in question. For example, NFiles * FileSizeMean / CycleTime
#   (FileSizeMean is set above) gives you the average rate of data 'flowing'
#   through your system. Each of those values can be set per workflow

#   This template will inject data, then subscribe it to T2s
    'RAW' => {
      CycleTime		=> 999_999_999, # Start another instance of this workflow every so often
      Events		=> [ 'makeDataset', 'makeBlocks', 'makeFiles', 'Inject', 'T2Subscribe', 'addData', ],
      Intervals			=> {
	Inject			=>    0,
	T2Subscribe		=>    3,
        addData			=>  300,
      },
      Priority		=> 'low',
      IsCustodial	=>   'n',
      IsMove		=>   'n',
      Group		=> 'operators',
    },
    CheckProxy => {
      Incarnations =>   1,
      NCycles	   =>   1,
      GracePeriod  => 600,
    },
    Auth => {
      Incarnations => 1,
      NCycles      => 1,
    },
  },

  Defaults => {
#   Use the Datasvc module to perform the actions, instead of calling the code directly.
    Namespace	=> 'PHEDEX::Testbed::Lifecycle',
    Module => {
      Auth               => 'Datasvc',
      Inject             => 'Datasvc',
      T1Subscribe        => 'Datasvc',
      T2Subscribe        => 'Datasvc',
      UpdateSubscription => 'Datasvc',
      srcdelete   => 'Datasvc',
      makeDataset => 'DataProvider',
      makeBlocks  => 'DataProvider',
      makeFiles   => 'DataProvider',
      addData     => 'DataProvider',
    },
    DataProvider => { # parameters for the DataProvider module constructor
      addData  => {
        addEvents => [ 'Inject', 'addData', ], # After running addData, push these events back onto the workflow
      },
    },
    Datasvc	=> { # parameters for the Datasvc module constructor

# Choose one or other pair here, but do _not_ choose the prod instance with phedex-web-dev!
      url      => 'https://brazil.accre.vanderbilt.edu:4443/phedex/datasvc',
      instance => 'prod',
#      url      => 'https://phedex-web-dev.cern.ch/phedex/datasvc',
#      instance => 'tbedii',

#      Set up your proxy by running 'voms-proxy-init --voms cms --valid 192:00'
       cert_file => $ENV{X509_USER_PROXY} || "/tmp/x509up_u$<",
       key_file	 => $ENV{X509_USER_PROXY} || "/tmp/x509up_u$<",
       ca_file	 => $ENV{X509_USER_PROXY} || "/tmp/x509up_u$<",
       ca_dir	 => $ENV{X509_CERT_DIR}   || '/afs/cern.ch/project/gd/LCG-share2/certificates',
    },
    Exec => {
#     External executables for some other actions
      'CheckProxy'	=> 'CheckProxy.pl',
    },
  },

# This is a hash of named workflows. Workflows are based on their 'Template' member,
# and may contain parameters that override the template, or simply add new data that
# is used by separate events in the workflow.
  Workflows => [
    {
      Name			=> 'Raw data',
      Template			=> 'RAW',
      Suspend			=> 0, # Enable/suspend this particular workflow

#     Injection parameters. Only one, so a simple scalar will do
      InjectionSite		=>    'T2_Test1_Buffer',

#     addData parameters. How to add data to this dataset
      InjectionsPerBlock	=>         4, # Use open blocks <n> times, then close them
      BlocksPerDataset		=>	 200, # Add <n> blocks to the dataset
      DropClosedBlocks		=>	   1, # Tidy up the dataset structure from time to time

#     Subscription parameters. Complex object, and can be multiple.
      T2Subscribe	=> {
        Nodes       => 'T2_Test2_Buffer',
      },

#     Initial parameters for the generator
      Dataset	=> '/tony/testInject-6-%04x/RAW',
      Datasets	=>     1,
      Blocks	=>     1,
      Files	=>   250,

#     Start another cycle once this one finishes
      AutoRestart => 1,

      DBS	=> 'http://cmsdoc.cern.ch/cms/aprom/DBS/CGIServer/query',
    },
    { Name => 'CheckProxy', },
    { Name => 'Auth', },
  ],

# These are in case I am using a PhEDEx::Logger to send stuff to. I'm not...
  QueueEntries  => 1,
  RetryInterval => 2,
);

do "$ENV{LIFECYCLE}/LifecycleNodes.pl";

do "$ENV{LIFECYCLE}/LifecycleGroups.pl";

# Everything below here can be ignored.
#%Logger::Receiver =
#(
#  ConfigRefresh	=> 10, # Interval for checking config file
#  Host		=> 'localhost',
#  Port		=> 22201,
## Logfile	=> /tmp/wildish/PhEDEx/logs/prototype.log,
#  Quiet		=> 0,
#  Verbose	=> 1,
#  Debug		=> 0,
#);
#
#%Logger::Sender =
#(
#  QueueEntries	=> 1,
#  RetryInterval => 2,
#  Quiet		=> 1,
#  Verbose	=> 0,
#  Debug		=> 0,
#);

1;
